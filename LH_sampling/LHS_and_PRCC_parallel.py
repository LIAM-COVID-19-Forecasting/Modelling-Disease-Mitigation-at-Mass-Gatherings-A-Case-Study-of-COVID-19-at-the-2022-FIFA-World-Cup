"""
Creation:
    Author: Martin Grunnill
    Date: 2022-10-05
Description: Generate Latin-Hypercube Sample (LHS), run simulations via parallel processing and calculate Partial
Correlation Coefficients. Recommend looking up
https://www.sciencedirect.com/science/article/abs/pii/S0022519308001896?via%3Dihub.

Note parallel processing can take up a lot of computing resources.

Functions
---------


run_samples_in_parrallell(sample_df, model_run_method, max_workers=None, return_focused_results=True, **kwargs)
    Runs model simulations using parameters in sample_df using parallel processing.
LHS_and_PRCC_parallel(parameters_df, sample_size, model_run_method,  results_csv = None, LHS_obj=None,
                      other_samples_to_repeat=None, max_workers=None)
    Generate a Latin Hypercube sample, run model with sample (in parallel) and calculate PRCC for sampled parameters.

"""
import pandas as pd
from scipy.stats import qmc
from tqdm.auto import tqdm
import concurrent
from LH_sampling.LHS_and_PRCC_serial import format_sample, calucate_PCC


def run_samples_in_parrallell(sample_df, model_run_method, max_workers=None, return_focused_results=True, **kwargs):
    """
    Runs model simulations using parameters in sample_df using parallel processing.

    Parameters
    ----------
    sample_df : pandas.Dataframe
        Parameter samples being run. Column fields are parameters.
    model_run_method : function
        Method of running model simulation. Must accept parameters as a single dictionary.
    max_workers : int, optional defaults to maximum available.
        Number of workers/cpu/cores used in running simulations.
    return_focused_results : bool, default True
        Return results as dataframe.
    kwargs : dictionary
        Key word arguments to pass to model_run_method.

    Returns
    -------
    If return_focused_results is True a pandas DataFrame of results is returned.
    """
    samples = sample_df.to_dict('records')
    with tqdm(total=len(sample_df),
              desc='Simulating LH Sample',
              position=1,
              leave=False,
              colour='green') as pbar: # add a progress bar.
        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor: # set up paralisation for simulations
            simlations = [executor.submit(model_run_method, sample, **kwargs) for sample in samples]
            focused_results_and_sample_records = []
            for simlation in concurrent.futures.as_completed(simlations):
                focused_results_and_sample_records.append(simlation.result())
                pbar.update(1)
    if return_focused_results:
        focused_results_and_sample_df = pd.DataFrame.from_records(focused_results_and_sample_records)
        return focused_results_and_sample_df


def LHS_and_PRCC_parallel(parameters_df,
                          sample_size,
                          model_run_method,
                          results_csv = None,
                          LHS_obj=None,
                          other_samples_to_repeat=None,
                          max_workers=None,
                          LHS_include_seed=True):
    """
    Generate a Latin Hypercube sample, run model with sample (in parallel) and calculate PRCC for sampled parameters.

    Parameters
    ----------
    parameters_df : pd.DataFrame
        DataFrame outlining the boundaries for each parameter. Must contain fields 'Lower Bound' and
        'Upper Bound'. Name of the parameters is assumed to be in the index.
    sample_size : int
        Sample size of Latin Hypercube.
    model_run_method : function
        Method of running model simulation. Must accept parameters as a single dictionary.
    results_csv : string, optional
        If given results are saved to csv instead of being returned as a dataframe.
    LHS_obj : scipy.stats.qmc.LatinHypercube, optional
        Pre-initialised Latin Hypercube sample generator. If not provided one is generated by the function.
    other_samples_to_repeat :
    max_workers : int, optional defaults to maximum available.
        Number of workers/cpu/cores used in running simulations
    LHS_include_seed : bool
        Include generation of a seed in Latin Hypercube sampling.

    Returns
    -------

    """
    if LHS_obj is None:
        num_LH_parameters_sampled = len(parameters_df)
        if LHS_include_seed:
            num_LH_parameters_sampled += 1
        LHS_obj = qmc.LatinHypercube(num_LH_parameters_sampled)
    LH_sample = LHS_obj.random(sample_size)
    sample_df, parameters_sampled = format_sample(parameters_df, LH_sample, other_samples_to_repeat,
                                                  include_seed=LHS_include_seed)
    focused_results_and_sample_df = run_samples_in_parrallell(sample_df, model_run_method, max_workers=max_workers)
    prccs = []
    for parameter in parameters_sampled:
        covariables = [item
                       for item in parameters_sampled
                       if item != parameter]
        for column in focused_results_and_sample_df.columns:
            if column not in parameters_sampled:
                param_rank_pcor = calucate_PCC(focused_results_and_sample_df, parameter, column, covariables, method='spearman')
                prccs.append(param_rank_pcor)

    prccs = pd.concat(prccs)
    prccs.sort_index(inplace=True)
    if results_csv is not None:
        prccs.to_csv(results_csv)
    else:
        return prccs

